<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<title>Photoconsistency-Visual-Odometry: Documentation Overview</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css"/>
</head>
<body onload='searchBox.OnSelectItem(0);'>
<!-- Generated by Doxygen 1.7.3 -->
<script type="text/javascript"><!--
var searchBox = new SearchBox("searchBox", "search",false,'Search');
--></script>
<div id="top">
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">Photoconsistency-Visual-Odometry</div>
   <div id="projectbrief">Multiscale Photoconsistency Visual Odometry from RGBD Images</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li class="current"><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="annotated.html"><span>Data&#160;Structures</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li id="searchli">
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
</div>
<div class="header">
  <div class="headertitle">
<h1>Documentation Overview </h1>  </div>
</div>
<div class="contents">
<div class="textblock"><h2><a class="anchor" id="intro_sec"></a>
Introduction</h2>
<p>This is the documentation of the Photoconsistency-Visual-Odometry project. This project implements a method to estimate the rigid transformation that best aligns a pair of RGBD frames based on the maximization of a photoconsistency error function for visual odometry applications. To estimate the rigid transformation, the method performs a photoconsistency error function optimization at different image scales.</p>
<div align="center">
<img src="PhotoconsistencyOdometryMap.png" alt="PhotoconsistencyOdometryMap.png"/>
<p><strong>Top view of an indoor 3D map reconstructed using the estimated Visual Odometry as a first pose approximation and GICP for pose refinement.</strong></p></div>
 <h2><a class="anchor" id="dependencies_sec"></a>
Dependencies</h2>
<p>This project uses several open-source libraries to build the whole solution. The main dependencies are:</p>
<ul>
<li>Ceres Solver: <a href="http://code.google.com/p/ceres-solver/">http://code.google.com/p/ceres-solver/</a></li>
<li>OpenCV: <a href="http://opencv.willowgarage.com/wiki/">http://opencv.willowgarage.com/wiki/</a></li>
<li>PCL: <a href="http://pointclouds.org/">http://pointclouds.org/</a></li>
<li>MRPT: <a href="http://www.mrpt.org/">http://www.mrpt.org/</a></li>
<li>Eigen: <a href="http://eigen.tuxfamily.org">http://eigen.tuxfamily.org</a></li>
</ul>
<h2><a class="anchor" id="install_sec"></a>
Installation</h2>
<p>This project has been implemented and tested in Ubuntu 11.04 and 11.10. To compile the source code you need to install the dependencies first. After that, follow the following steps to compile the project.</p>
<ul>
<li>Substitute the ceres-solver/include/ceres/jet.h header by the one inside PhotoconsistencyVisualOdometry/third_party/jet.h.</li>
</ul>
<ul>
<li>Generate the Code::Blocks project.<ol type="a">
<li>Open CMake.</li>
<li>Set the source directory to PhotoconsistencyVisualOdometry and the build directory to PhotoconsistencyVisualOdometry/build.</li>
<li>Set OpenCV_DIR and MRPT_DIR to the OpenCV and MRPT build directories respectively.</li>
<li>Specify the Ceres include directory (ceres-solver/include) to the CERES_INCLUDE_DIRECTORY variable.</li>
<li>Specify the Ceres library directory (ceres-solver_build/internal/ceres) to the CERES_LIB_DIRECTORY variable.</li>
<li>Configure.</li>
<li>Generate.</li>
</ol>
</li>
</ul>
<ul>
<li>Compile the PhotoconsistencyVisualOdometry project.<ol type="a">
<li>Open the PhotoconsistencyVisualOdometry/build/PhotoconsistencyVisualOdometry.cbp project.</li>
<li>Compile.</li>
</ol>
</li>
</ul>
<ul>
<li>[optional] Install CVPR tools dependencies and download the CVPR tools inside the PhotoconsistencyVisualOdometry/tools/rgbd_benchmark_tools directory. <div class="fragment"><pre class="fragment">
sudo apt-get install python-numpy
sudo apt-get install python-matplotlib 
cd PhotoconsistencyVisualOdometry/tools
svn co https://svncvpr.in.tum.de/cvpr-ros-pkg/trunk/rgbd_benchmark/rgbd_benchmark_tools/src/rgbd_benchmark_tools/
</pre></div></li>
</ul>
<ul>
<li>[optional] Download the file 'rigid_transform_3D.m' inside the PhotoconsistencyVisualOdometry/tools/plot_trajectory_tools directory. The file can be found in the following link: <a href="http://nghiaho.com/uploads/code/rigid_transform_3D.m">http://nghiaho.com/uploads/code/rigid_transform_3D.m</a> <div class="fragment"><pre class="fragment">
cd PhotoconsistencyVisualOdometry/tools/plot_trajectory_tools
wget http://nghiaho.com/uploads/code/rigid_transform_3D.m
</pre></div></li>
</ul>
<h2><a class="anchor" id="usage_sec"></a>
Software usage</h2>
<p>After compiling the project, two executables should appear in the PhotoconsistencyVisualOdometry/build directory. The program PhotoconsistencyFrameAlignment estimates the 3DoF/6DoF rigid body motion between two RGBD frames loaded from file and shows the resulting difference image (Note: the 3DoF warping function is not yet implemented). The program PhotoconsistencyVisualOdometry estimates the trajectory of the Kinect sensor using a pairwise alignment approach. This program generates 3D point clouds transformed to the same reference frame to show the alignment results. The RGB-D data can be provided using a file interface that grabs RGB-D frames from .rawlog datasets using the MRPT library (TODO: in the following releases, an OpenNI interface will be added to allow online operation). In the following link there are some RGB-D datasets (.rawlog) that can be used to test the programs.</p>
<p><a href="http://www.mrpt.org/robotic_datasets">http://www.mrpt.org/robotic_datasets</a></p>
<p>The original datasets can be found in the following link. However they are not prepared to be used in this sofware.</p>
<p><a href="http://cvpr.in.tum.de/data/datasets/rgbd-dataset">http://cvpr.in.tum.de/data/datasets/rgbd-dataset</a></p>
<p>These RGB-D datasets also contain a very precise ground-truth that can be very useful to evaluate different configurations. In the previous link, the CVPR group also provides a set of tools to measure the error between the estimated trajectory and the real trajectory of the ground-truth.</p>
<h3><a class="anchor" id="PhotoconsistencyFrameAlignment"></a>
PhotoconsistencyFrameAlignment</h3>
<p>This program estimates the 3DoF/6DoF rigid transformation between two RGBD frames loaded from file, maximizing the photoconsistency between the warped source intensity image and the target intensity image. To configure the optimization process, provide a configuration file to the algorithm like the ones in the PhotoconsistencyVisualOdometry/config_files directory.</p>
<div class="fragment"><pre class="fragment">
cd PhotoconsistencyVisualOdometry/build
./PhotoconsistencyFrameAlignment &lt;config_file.yml&gt; &lt;imgRGB0.png&gt; &lt;imgDepth0.png&gt; &lt;imgRGB1.png&gt;
</pre></div><div align="center">
<img src="PhotoconsistencyDifferenceImage.png" alt="PhotoconsistencyDifferenceImage.png"/>
<p><strong>OpenCV window that shows the resulting difference image from the photoconsistency maximization process.</strong></p></div>
 <h3><a class="anchor" id="PhotoconsistencyVisualOdometry"></a>
PhotoconsistencyVisualOdometry</h3>
<p>This program estimates the trajectory of the sensor and generates a 3D map from the provided secuence of RGB-D frames. The program stores the results in the PhotoconsistencyVisualOdometry/results directory. The program generates .pcd files representing each keyframe transformed to the original reference frame. These files are generated in the PhotoconsistencyVisualOdometry/results/pcd_files directory. The program can be compiled to use an Iterative Closest Point algorithm to refine the estimated rigid transformation. To refine the rigid transformation using ICP (recommended), set the ENABLE_ICP_POSE_REFINEMENT define to 1. Another useful feature is the possibility to save the estimated trajectory (and ground-truth if provided) to file. This is useful to visualize the estimated trajectory, as well as to compare it with the ground-truth using the CVPR tools. If you don't need to visualize or compare the estimated and ground-truth trajectories, simply set the ENABLE_SAVE_TRAJECTORY to 0.</p>
<p>The rest of the configuration parameters can be passed to the program through the command line. The main parameters are the ground-truth file, to compare with the estimated trajectory (needs the CVPR tools) and the Iterative Closest Point method used to refine the pose.</p>
<div class="fragment"><pre class="fragment">
cd PhotoconsistencyVisualOdometry/build
./PhotoconsistencyVisualOdometry &lt;config_file.yml&gt; &lt;rawlog_file.rawlog&gt; [options]
       options: 
               -g          Ground truth file &lt;groundtruth.txt&gt;
               -m          Iterative Closest Point method:
                           0: GICP
                           1: ICP-LM
                           2: ICP
               -d          Maximum correspondence distance (ICP/ICP-LM/GICP):
               -r          Ransac outlier rejection threshold (ICP/ICP-LM/GICP):
               -i          Maximum number of iterations (ICP/ICP-LM/GICP):
               -e          Transformation epsilon (ICP/ICP-LM/GICP):
               -s          Skip X frames. Process only one of X frames:
</pre></div><p>If you compile the program to save the trajectory, three files ("poses.mat", "trajectory.txt" and "estimated_trajectory.eps") will be saved to the PhotoconsistencyVisualOdometry/results directory: the first file contains the sequence of estimated poses (each row represents the 16 elements of a 4x4 rigid transformation matrix); the second file contains the same sequence of poses with timestamps, but using a 3D+Quaternion representation (to be used with the CVPR tools); the last file is a figure that shows the 2D top view of the sequence of poses (note: requires Octave to draw the trajectory).</p>
<p>Furthermore, if you provide a ground-truth file to the program, three more files ("groundtruth.txt", "trajectory.pdf" and "ground-truth_and_estimated_trajectory.eps") will be added to the PhotoconsistencyVisualOdometry/results directory: the first file is simply a copy of the provided ground-truth file; the second is the output file from the evaluate_ate.py CVPR tool, that shows the estimated trajectory and pose differences drawn over the ground-truth (note: requires the CVPR tools dependencies installed); the third file is a figure that shows the estimated trajectory over the ground-truth in the reference frame of the first RGBD frame (note: requires Octave and the file rigid_transform_3D.m).</p>
<h3><a class="anchor" id="A"></a>
Global map visualization</h3>
<p>As said before, the PhotoconsistencyVisualOdometry program generates ".pcd" files inside the PhotoconsistencyVisualOdometry/results/pcd_files directory. These files contain the point cloud of each keyframe transformed to the same reference frame. To visualize the global map simply run the pcd_viewer tool from the PCL library with all or a subset of the generated ".pcd" files.</p>
<div class="fragment"><pre class="fragment">
cd PhotoconsistencyVisualOdometry/build
../results/pcd_files/*.pcd 
</pre></div><div align="center">
<img src="PhotoconsistencyOdometry3DMap.png" alt="PhotoconsistencyOdometry3DMap.png"/>
<p><strong>PCL window that shows the generated global map of an indoor scene reconstructed using the Photoconsistency Visual Odometry as a first pose approximation and GICP for pose refinement. The results are stored in separate transformed_keyframe_x.pcd files that represent each keyframe point cloud transformed to the same reference frame; to open the .pcd files use the pcd_viewer tool of the PCL library.</strong></p></div>
 <h3><a class="anchor" id="B"></a>
CVPR tools</h3>
<p>If you have the CVPR tools dependencies installed and have compiled the PhotoconsistencyVisualOdometry program to save the trajectories, the program will execute the evaluate_ate.py and evaluate_rpe.py tools that compute the absolute and relative error of the estimated trajectory compared to the ground-truth. Additionally, to visualize the goodness of the estimated trajectory, a ".pdf" file will be generated inside the PhotoconsistencyVisualOdometry/results directory, representing the ground-truth and the estimated trajectory seen from above.</p>
<div align="center">
<img src="trajectory.svg" alt="trajectory.svg"/>
<p><strong>Estimated trajectory and pose differences drawn over the ground-truth using the CVPR tools.</strong></p></div>
 <h3><a class="anchor" id="C"></a>
Octave visualization scripts</h3>
<p>Other useful tools for visualization are the "plot_odometry.m" and "plot_trajectory_groundtruth_estimated.m" Octave scripts: the first script loads the "poses.mat" file generated inside the PhotoconsistencyVisualOdometry/results (if compiled to save the trajectory) and plots all the estimated poses as seen from above; the second, plots the estimated trajectory and ground-truth as seen from above.</p>
<div align="center">
<img src="estimated_trajectory.svg" alt="estimated_trajectory.svg"/>
<p><strong>Estimated trajectory displayed using the plot_odometry.m script.</strong></p></div>
 <div align="center">
<img src="ground-truth_and_estimated_trajectory.svg" alt="ground-truth_and_estimated_trajectory.svg"/>
<p><strong>Estimated trajectory over the ground-truth using the Octave 'plot_trajectory_groundtruth_estimated.m' script.</strong></p></div>
 <dl class="author"><dt><b>Author:</b></dt><dd>Miguel Algaba Borrego <br/>
 <a href="http://thecomputervision.blogspot.com/">http://thecomputervision.blogspot.com/</a> </dd></dl>
</div></div>
<!--- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Data Structures</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Functions</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(3)"><span class="SelectionMark">&#160;</span>Variables</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<hr class="footer"/><address class="footer"><small>Generated on Sun Jul 22 2012 12:53:03 for Photoconsistency-Visual-Odometry by&#160;
<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.7.3 </small></address>
</body>
</html>
